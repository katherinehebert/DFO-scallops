---
output: 
  pdf_document:
    template: eisvogel.tex
title: "Scallop trends with `DLMtool`"
author: [Katherine Hébert]
date: "2021-08-13"
subtitle: "BIOS² Internship with Fisheries and Oceans Canada"
lang: "en"
titlepage: true,
titlepage-text-color: "FFFFFF"
titlepage-rule-color: "FFFFFF"
titlepage-rule-height: 2
titlepage-background: "background.pdf"
bibliography: master.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(DLMtool)  
theme_set(ggpubr::theme_pubclean())
```

# Context

## Scallops fishery

Two scallop species are fished commercially in the Gulf of St. Lawrence: the Sea Scallop (*Placopecten magellanicus*) and the Iceland Scallop (*Chlamys islandica*) [@stockass]. Fishing is regulated by a fishing season, and or a limited number of fishing days [@stockass]. Every three years, the scallop stock is assessed to evaluate its status, and to verify whether the management plan and conservation approach need to be adjusted to maintain the resource [@stockass]. This assessment is based on landings, fishing effort, catch per unit effort, size structure, weight of muscle landed and density index from scientific surveys [@stockass].

The scallop fishery is data-limited in the Gulf of St. Lawrence, meaning there is not enough data to conduct a conventional stock assessment. This is where the Data-Limited Methods Toolkit (`DLMtool`) comes into play.

## `DLMtool`

The Data-Limited Methods Toolkit ([`DLMtool`](https://www.datalimitedtoolkit.org/)) is an R package that was conceived to address a widespread problem in fisheries management: conventional stock assessments require a lot of data that is not available for as many as 90% of the world's fish populations [@Costello517]. Using object-oriented programming and parallel computing, `DLMtool` models data-limited fisheries under a variety of management strategies that can easily be compared and visualized according to the available information [@`DLMtool`]. This allows managers to simulate a variety of management scenarios with an evaluation of uncertainty, of the trade-off between how management procedures benefit catch or population stability, and of the potential need to collect additional data. The result is a powerful and customisable simulation and diagnostics tool that synthesizes scenarios of over 114 management procedures to inform management recommendations in a transparent way [@`DLMtool`]. What began as a collaboration between the University of British Columbia's (UBC) Institute for Oceans and Fisheries and the Natural Resources Defense Council (NRDC) has now been used in over 25 fisheries by Fisheries and Oceans Canada, by the National Marine Fisheries Service in the U.S. Mid-Atlantic and Caribbean regions, and by the California Department of Fish & Wildlife, among others [@`DLMtool`].

## Objectives

The internship's main objective is to learn and apply the Data-Limited Methods Toolkit to evaluate scallop stocks. The first objective was to learn the toolkit and describe the main findings in the current report, with the option to a method with high performance to model scallop stocks if time permits. Though time did not permit me to go in much depth with this, I was able to construct some of the objects used in the DLM toolkit workflow to eventually evaluate stocks with greater accuracy and precision. In this report, I will begin by outlining some general trends in scallop catches, length structures, and mortality rates, before describing how I built objects with these datasets using `DLMtool`. All scripts to generate the figures and results shown in this report are accessible here: **REPO LINK**.

------------------------------------------------------------------------

# Exploring trends

Before using `DLMtool`, I first explored the time series in the data provided to me to better understand the system. I first looked at catch data, which contained information about the biomass of the scallop catch per year in each surveyed zone, as well as the effort applied to the catch. After exploring the annual catch trend, I added length-at-capture data to look into the size structure of the catch, which would give insight into the population's structure. I also introduced mortality data into these explorations, to determine how scallop mortality varied (or not) over the sampled period, which would give additional insight into the population's status.

## Catch

First, I explored the commercial fishery dataset which contained Catches per Unit Effort (CPUE), and data describing the Effort, biomass fished (i.e. Landings), and other information describing each event such as date and location variables. These time series are plotted in Figures 1a and 1b. Though the Survey CPUE time series shows relative stability through time in terms of mean CPUE, there is some variability in the variance in CPUE across sectors, with particularly high variance in the years 2018, 1999, and 1996 (Figure 1a).

Then, I fit a simple linear model to each time series to determine an overall trend through time for each measure (Figure 1c and 1d). While CPUE has remained relatively stable since 1987 (Figure 1c), landings have been steadily decreasing at a rate of -29.39 **tons per year????** since 1987 despite a large increase before 1990 (Figure 1d).

![**Overview of landing and Survey CPUE trends over all years and all sectors.** (a) Landings in tonnes over all years available in the dataset, summed across all sectors. (b) Survey Catches per Unit Effort (CPUE), where points indicate the mean CPUE and the error bars show the 95% confidence intervals around the mean. Panels (c) and (d) show linear models fit to the time series plotted in (a) and (b), with model summary information printed in the figure caption.](figures/CPUE_Landings_Historical.png)

Though an overview of the whole time series is very helpful to gain an understanding of the broader context of the fishery and how it has been managed, a closer look at recent trends is helpful to evaluate the current status of the fishery (Figure 2). If we "zoom in" to the most recent 5 years, we get a slightly different picture of the Survey CPUE and Landings trends shown above. Notably, we can see that an average increase in Survey CPUE in 2018 (Figures 2a and 2c) was followed by a decrease in landings between 2018 and 2019 (Figures 2b and 2d).

![**Landings and Survey CPUE over the 5 most recent years.** (a) Landings in tonnes over all years available in the dataset, summed across all sectors. (b) Survey Catches per Unit Effort (CPUE), where points indicate the mean CPUE and the error bars show the 95% confidence intervals around the mean. Panels (c) and (d) show linear models fit to the time series plotted in (a) and (b), with model summary information printed in the figure caption.](figures/CPUE_Landings_05Recent.png)

Both plots and analyses in Figures 1 and 2 were adapted from @refpoint [github.com/MathBoud/DLM.ReferencePoint](https://github.com/MathBoud/DLM.ReferencePoint). The code to reproduce these figures **is in the script \_\_\_\_ in the repo \_\_\_\_\_\_\_\_\_**.

## Length

Though the overall trend is informative, I also had access to a survey of scallop length frequencies through time, which offer insight into the Gulf population's structure that is not accessible in the overall catch and landings time series explored above. 

  First, I took the weighted mean of scallop length per year, where the weights were the counts of scallops in each length category. As such, the weighted mean represents the mean length of the population for each year, accounting for the abundance of scallops at different lengths.

  To determine the trend in mean length over the time series, I compared a simple linear model of the relationship between mean length and year to two linear mixed models: one with a random effect by sector on the model intercept, and one with a random effect on the slope by sector, to account for differences in the populations between sectors:

$$m_0 = Length_{mean} \sim {Year}$$
$$m_1 = Length_{mean} \sim Year + (1 | Sector)$$
$$m_2 = Length_{mean} \sim (Year | Sector)$$


  Though there is some variability in the mean length trend in different sectors (**ref**), the simple linear model was selected as the best option of the three proposed models according to its Akaike Information Criterion (AIC). This model showed an overall decline in the weighted mean length of scallops in the time series, with a slope of -1.1167 (Fig. 3).

```{r, echo = FALSE, message=FALSE, warning=FALSE}
library(dplyr)
aic <- readRDS("outputs/model_length_AIC.rds") 
aic <- aic[, which(colnames(aic) %in% c("class", "df", "logLik", "AICc", "delta"))]

kableExtra::kable(aic) %>% 
  kableExtra::kable_styling(full_width = TRUE)
```

![**Mean trend through time of the mean density of scallops per length over all surveyed sectors.** *The solid black line is a linear model describing the change in weighted mean length of scallops surrounded by its 95% confidence intervals.*](figures/meanlengths_lm_boxplot.png)

  However, there were still some interesting differences between sectors in the mixed models ($m_1$ and $m_2$). When a random effect was applied to the slope of length through time, sectors varied in the magnitude and direction of the slopes (Fig. 4), where length increased in sectors A, P, O, M, N, E and decreased in all other sectors to varying degrees. 

![**Slope of the mean density of scallops per length over time, in each surveyed sectors.**](figures/meanlengths_lmm_slopespersector.png)

Length frequency surveys provide information about the proportion of the scallop population which has attained maturity, which is an indicator of population renewal. Following a script written by @refpoint, I calculated Froese Length Indicators [@froese2004keep], namely to determine what proportion of scallops were at or above maturity length. I then applied a linear model to evaluate the change in this proportion of scallops are maturity length over time, to determine whether the Gulf population structure had changed throughout the time series (Fig. 5). The linear model reveals that the frequency of mature scallops have been declining, though the mean proportion of mature scallops has increased in the last 5 years (Fig. 5).

![**Mean trend through time of the mean density of scallops at maturity over all surveyed sectors.** *The solid blue line is a linear model describing the change in density of scallops at maturity surrounded by its 95% confidence intervals. The solid black line shows the calculated proportion of scallops at maturity length, on which the linear model was fit.*](figures/Percent_MatureScallops.png)

## Mortality

Mortality rates in the scallop population can also provide valuable insight into the status of the Gulf population. I subset the dataset describing scallop mortality frequencies to the years between 2004 and 2019, because the methodology prior to 2004 yielded less precise measurements of mortality and were therefore not comparable to the 2004-2019 period. Not surprisingly, there generally tend to be more living than dead scallops across all years and all sectors, though the difference between these two categories is variable (Fig. 6).

![**Frequency of living (VIV) and dead (MOR) scallops annually in each sector**.](figures/mortality_barplot.png)

To analyze the trend in mortality rate more generally, I calculated the ratio between living and dead scallops as $ratio = MOR/VIV$ after summing frequencies across all sectors, for each year. This model shows that over the entire time series, this ratio remained stable despite some fluctuations between different years.

![Annual mortality ratio (MOR/VIV Ratio) across all sectors. *The solid blue line is a linear model describing the change in the MOR/VIV ratio of scallops surrounded by its 95% confidence intervals. Black points show the calculated MOR/VIV ratio after summing frequencies across all sectors, for each year.*](figures/mortality_overall.png)

This mortality ratio was also calculated for each sector and each year, to assess whether certain sectors differed in mortality trends. Although the overall trend was relatively constant, some sectors did differ in the slope of the change in the ratio through time, including noticeable increases in mortality in sectors E, G, Q, and notable declines in mortality in sectors B, J, and P (Fig. 7).

![Annual mortality ratio (MOR/VIV Ratio) in each sector. *Facet labels identify each sector's ID. The solid line is a linear model describing the change in the MOR/VIV ratio of scallops surrounded by its 95% confidence intervals. Black points show the calculated MOR/VIV ratio for each year in each sector.*](figures/mortality_persector.png)


------------------------------------------------------------------------

# `DLMtool` with the CPUE dataset

## Data object

First, I created a catch matrix, and average catch matrix, and a mean effort matrix:

```{r, message=FALSE}
# read the prepared data (generated with 01_dataprep.R)
cpue <- read_csv("data/scallop-cpue.csv")

# make matrix of nsim rows and nyears columns for catch data
catch_matrix <- pivot_wider(subset(cpue, select = c(Year, CPUE_hm)), 
                            names_from = Year,
                            values_from = CPUE_hm,
                            values_fn = function(x) {sum(x, na.rm = TRUE)}) %>% 
  as.matrix()

# make average catch matrix
avc_matrix <- group_by(cpue, Year) %>% 
  summarise(Avc = mean(CPUE_hm, na.rm = TRUE))

# make effort matrix of nsim rows and nyears columns
effort_matrix <- pivot_wider(subset(cpue, select = c(Year, Effort_hm)), 
                            names_from = Year,
                            values_from = Effort_hm,
                            values_fn = function(x) {mean(x, na.rm = TRUE)}) %>% 
  as.matrix()
```

Then, I created a Data object with `DLMtool`, and filled it with the available information in the dataset:

```{r, message=FALSE}
# create data object
scallops <- new('Data')
# populate the data file
scallops@Name <- "Data"
scallops@Common_Name <- "Scallop"
scallops@LHYear <- max(cpue$Year)
scallops@Units <- "kg/hm"
scallops@Effort <- effort_matrix 
scallops@nareas <- length(unique(cpue$Div))  
scallops@Year <- unique(cpue$Year)
scallops@Cat <- catch_matrix
scallops@AvC <- avc_matrix$Avc
scallops@t <- length(unique(cpue$Year))
scallops@MPeff <- 1 # set to today's effort for comparison
```

## TACs

Even with such little data, it is possible to apply several Management Procedures to the Data object to generate Total Allowable Catch recommendations.

```{r, message=FALSE}
# which MPs can be applied?
Can(scallops)
```

Then, Total Allowable Catch recommendations can be obtained for each of the evaluated MPs.

```{r, message=FALSE, echo = FALSE}
TACs <- readRDS("outputs/TACs_DLMtool_cpue.rds") %>% boxplot()
```


# `DLMtool` with Length Frequency dataset

### Creating the Data object





# `DLMtool` with Mortality dataset

## Creating a Fleet object

## Creating an Operating Model

\newpage

# References
